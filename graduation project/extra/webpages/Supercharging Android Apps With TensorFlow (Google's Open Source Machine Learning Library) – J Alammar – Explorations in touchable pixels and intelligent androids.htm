<!DOCTYPE html> 
 <html><head> 
     <title>Supercharging Android Apps With TensorFlow (Google's Open  
 Source Machine Learning Library) – J Alammar – Explorations in touchable 
  pixels and intelligent androids</title> 
  
         <meta charset="utf-8"> 
     <meta content="text/html; charset=UTF-8" http-equiv="Content-Type"> 
     <meta http-equiv="X-UA-Compatible" content="IE=edge"> 
     <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"> 
  
      
     <meta name="description" content=" 
  
 In November 2015, Google announced and open sourced TensorFlow, its latest and greatest machine learning library. This is a big deal for three reasons: 
  
  
 Machine Learning expertise: Google is a dominant force in machine learning. Its prominence in search owes a lot to the strides it achieved in machine learning.  
 Scalability: the announcement noted that TensorFlow was initially designed for internal use and that it's already in production for some live product features. 
 Ability to run on Mobile. 
  
  
 This last reason is the operating reason for this post since we'll be focusing on Android. If you examine the tensorflow repo on GitHub, you'll find a little  tensorflow/examples/android directory. I'll try to shed some light on the Android TensorFlow example and some of the things going on under the hood. 
 "> 
     <meta property="og:description" content=" 
  
 In November 2015, Google announced and open sourced TensorFlow, its latest and greatest machine learning library. This is a big deal for three reasons: 
  
  
 Machine Learning expertise: Google is a dominant force in machine learning. Its prominence in search owes a lot to the strides it achieved in machine learning.  
 Scalability: the announcement noted that TensorFlow was initially designed for internal use and that it's already in production for some live product features. 
 Ability to run on Mobile. 
  
  
 This last reason is the operating reason for this post since we'll be focusing on Android. If you examine the tensorflow repo on GitHub, you'll find a little  tensorflow/examples/android directory. I'll try to shed some light on the Android TensorFlow example and some of the things going on under the hood. 
 "> 
      
     <meta name="author" content="J Alammar"> 
  
      
     <meta property="og:title" content="Supercharging Android Apps With TensorFlow (Google's Open Source Machine Learning Library)"> 
     <meta property="twitter:title" content="Supercharging Android Apps With TensorFlow (Google's Open Source Machine Learning Library)"> 
      
  
     <!--[if lt IE 9]> 
       <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script> 
     <![endif]--> 
  
     <link rel="stylesheet" type="text/css" href="Supercharging%20Android%20Apps%20With%20TensorFlow%20%28Google%27s%20Open%20Source%20Machine%20Learning%20Library%29%20%E2%80%93%20J%20Alammar%20%E2%80%93%20Explorations%20in%20touchable%20pixels%20and%20intelligent%20androids_files/style.css"> 
     <link rel="alternate" type="application/rss+xml" title="J Alammar - Explorations in touchable pixels and intelligent androids" href="https://jalammar.github.io/feed.xml"> 
  
     <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now --> 
   </head> 
  
   <body> 
     <div class="wrapper-masthead"> 
       <div class="container"> 
         <header class="masthead clearfix"> 
           <a href="https://jalammar.github.io/" class="site-avatar"><img src=""></a> 
  
           <div class="site-info"> 
             <h1 class="site-name"><a href="https://jalammar.github.io/">J Alammar</a></h1> 
             <p class="site-description">Explorations in touchable pixels and intelligent androids</p> 
           </div> 
  
           <nav> 
             <a href="https://jalammar.github.io/">Blog</a> 
             <a href="https://jalammar.github.io/about">About</a> 
           </nav> 
         </header> 
       </div> 
     </div> 
  
     <div id="main" role="main" class="container"> 
       <article class="post"> 
   <h1>Supercharging Android Apps With TensorFlow (Google's Open Source Machine Learning Library)</h1> 
  
   <div class="entry"> 
     <p><img src="Supercharging%20Android%20Apps%20With%20TensorFlow%20%28Google%27s%20Open%20Source%20Machine%20Learning%20Library%29%20%E2%80%93%20J%20Alammar%20%E2%80%93%20Explorations%20in%20touchable%20pixels%20and%20intelligent%20androids_files/google-tensorflow-android.jpg" alt="google-tensorflow-android.jpg"></p> 
  
 <p>In November 2015, Google <a href="https://googleblog.blogspot.com/2015/11/tensorflow-smarter-machine-learning-for.html">announced</a> and open sourced <a href="https://www.tensorflow.org/">TensorFlow</a>, its latest and greatest machine learning library. This is a big deal for three reasons:</p> 
  
 <ol> 
 <li>Machine Learning expertise: Google is a dominant force in machine  
 learning. Its prominence in search owes a lot to the strides it achieved 
  in machine learning. </li> 
 <li>Scalability: the announcement noted that TensorFlow was initially  
 designed for internal use and that it's already in production for some  
 live product features.</li> 
 <li>Ability to run on Mobile.</li> 
 </ol> 
  
 <p>This last reason is the operating reason for this post since we'll be focusing on Android. If you examine the <a href="https://github.com/tensorflow/tensorflow">tensorflow repo on GitHub</a>, you'll find a little  <a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android">tensorflow/examples/android</a> directory. I'll try to shed some light on the Android TensorFlow example and some of the things going on under the hood.</p> 
  
 <!--more--> 
  
 <h2>A Look of Recognition</h2> 
  
 <p>The app glances out through your camera and tries to identify the  
 objects it sees. Sometimes it does a good job, other times it can't  
 quite pin down the object, and at times it leads to thought provoking  
 guesses! Overall, it feels pretty magical.</p> 
  
 <p><img src="Supercharging%20Android%20Apps%20With%20TensorFlow%20%28Google%27s%20Open%20Source%20Machine%20Learning%20Library%29%20%E2%80%93%20J%20Alammar%20%E2%80%93%20Explorations%20in%20touchable%20pixels%20and%20intelligent%20androids_files/android_tensorflow_classifier_results.jpg" alt="android_tensorflow_classifier_results.jpg"></p> 
  
 <p>The app accomplishes this feat using a bundled machine learning model 
  running in TensorFlow on the device (no network calls to a backend  
 service). The model is trained against millions of images so that it can 
  look at the photos the camera feeds it and classify the object into its 
  best guess (from the 1000 object classifications it knows). Along with  
 its best guess, it shows a confidence score to indicate how sure it is  
 about its guess.</p> 
  
 <p>The Android example page gives you an idea on how to build the app, and ultimately culminates in producing <a href="https://s3.amazonaws.com/jalammar.github.io/tensorflow_demo.apk">this APK</a> 
  (I built and uploaded the APK to save you some time since the building  
 process requires installing the Android NDK and Bazel, Google's build  
 tool).</p> 
  
 <p>NOTE: Android 5.0 or later required since the example uses the <a href="https://jalammar.github.io/Supercharging-android-apps-using-tensorflow/android.hardware.camera2">Camera2</a> package introduced in Android 5.0.</p> 
  
 <p>NOTE: if your device runs Android 6.0 or later, you have to install  
 the app with the following command (It gives the app the appropriate  
 permissions it needs to run): </p> 
 <div class="highlight"><pre><code class="language-text" data-lang="text">    adb install -r -g /path/to/apk.apk 
 </code></pre></div> 
 <h2>App Structure Walkthrough</h2> 
  
 <p><img src="Supercharging%20Android%20Apps%20With%20TensorFlow%20%28Google%27s%20Open%20Source%20Machine%20Learning%20Library%29%20%E2%80%93%20J%20Alammar%20%E2%80%93%20Explorations%20in%20touchable%20pixels%20and%20intelligent%20androids_files/android-tensorflow-app-structure_1.png" alt="android-tensorflow-app-structure_1.png"></p> 
  
 <p>The core TensorFlow engine is built with C++, but programmers can  
 write their TensorFlow software in either C++ or Python. The Android  
 TensorFlow example uses the C++ interface in the following manner:</p> 
  
 <ol> 
 <li>On startup, the app launches an Android activity (<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/CameraActivity.java">CameraActivity.java</a>) which then starts a fragment (<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/CameraConnectionFragment.java">CameraConnectionFragment.java</a>)</li> 
 <li>The fragment does some setup to basically start the camera and feed the incoming stream of images to an object it instantiates (<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/TensorflowImageListener.java">TensorflowImageListener.java</a>)</li> 
 <li>The listener consults the classifier (<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/TensorflowClassifier.java">TensorflowClassifier.java</a>) about each image it gets, and receives the classification and confidence score for each image.</li> 
 </ol> 
  
 <p>The good thing is that most of this logic is in normal Android Java  
 SDK territory -- so this should be familiar to most Android devs. So  
 where is the C++?</p> 
  
 <p><img src="Supercharging%20Android%20Apps%20With%20TensorFlow%20%28Google%27s%20Open%20Source%20Machine%20Learning%20Library%29%20%E2%80%93%20J%20Alammar%20%E2%80%93%20Explorations%20in%20touchable%20pixels%20and%20intelligent%20androids_files/android-tensorflow-app-structure_2.png" alt="android-tensorflow-app-structure_2.png"></p> 
  
 <p>If you look closely at TensorflowClassifier, you may notice the following methods:</p> 
 <div class="highlight"><pre><code class="language-java" data-lang="java">    <span class="kd">public</span> <span class="kd">native</span> <span class="kt">int</span> <span class="nf">initializeTensorflow</span><span class="o">(</span> <span class="o">);</span> 
  
     <span class="kd">private</span> <span class="kd">native</span> <span class="n">String</span> <span class="nf">classifyImageBmp</span><span class="o">(</span><span class="n">Bitmap</span> <span class="n">bitmap</span><span class="o">);</span> 
 </code></pre></div> 
 <p>The <code>native</code> keywords in these method signatures indicate  
 that these methods are implemented in native C++ code. Look for them  
 under the "android/jni" directory and true enough, you'll find <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/jni/tensorflow_jni.cc">tensorflow_jni.cc</a></p> 
 <div class="highlight"><pre><code class="language-c++" data-lang="c++">    <span class="n">JNIEXPORT</span> <span class="n">jint</span> <span class="n">JNICALL</span> 
     <span class="nf">TENSORFLOW_METHOD</span><span class="p">(</span><span class="n">initializeTensorflow</span><span class="p">)(...)</span> <span class="p">{</span> 
     <span class="p">...</span> 
     <span class="p">}</span> 
  
  
     <span class="n">JNIEXPORT</span> <span class="n">jstring</span> <span class="n">JNICALL</span> 
     <span class="nf">TENSORFLOW_METHOD</span><span class="p">(</span><span class="n">classifyImageBmp</span><span class="p">)(...)</span> <span class="p">{</span> 
     <span class="p">...</span> 
     <span class="p">}</span> 
 </code></pre></div> 
 <p><a href="https://developer.android.com/training/articles/perf-jni.html">JNI</a> 
  (short for Java Native Interface) is a way in which the Java parts of  
 an Android app can communicate with the native C++ parts. So when we  
 call <code>classifyImageBmp(bitmap)</code> in our Java code, it will actually invoke the C++ function exported in tensorflow_jni.cc and return the value it returns.</p> 
  
 <p>A Bitmap file cannot directly be sent to TensorFlow as input. It has  
 be transformed into an input tensor that we'd send in step #2 in the  
 flow above. A tensor is an n-dimensional array of values, and is the  
 motif TensorFlow uses to send data between all of its different  
 parts/operations. This model expect a 3-dimensional array that supplies  
 the Red/Green/Blue value of each pixel in the image. The dimensions are:</p> 
  
 <ol> 
 <li>X-index of the pixel</li> 
 <li>Y-index of the pixel</li> 
 <li>indication of which value this cell holds (0 for red, 1 for green, 2 for blue)</li> 
 </ol> 
  
 <p>And the value of the cell would be the actual value of R or G or B channel for that pixel.</p> 
  
 <p><img src="Supercharging%20Android%20Apps%20With%20TensorFlow%20%28Google%27s%20Open%20Source%20Machine%20Learning%20Library%29%20%E2%80%93%20J%20Alammar%20%E2%80%93%20Explorations%20in%20touchable%20pixels%20and%20intelligent%20androids_files/input_tensor.png" alt="input_tensor.png"></p> 
  
 <p>(This is somewhat oversimplified. I glanced over two things for  
 simplicity's sake. First is the conversion from the YUV format that the  
 Android camera exports to the RGB format the model expects. Second is  
 that the model actually takes a 4-dimensional tensor, but these three  
 are the ones we care about)</p> 
  
 <h2>The Model</h2> 
  
 <p>As you read the example's <a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android">README.md</a>, you'll notice that it instructs you to download a zip file containing the TensorFlow model and add it to the <code>assets</code> directory. This zip file contains two files that are important for us:</p> 
  
 <ol> 
 <li><p><code>tensorflow_inception_graph.pb</code>- At 54 MBs unzipped,  
 this file constitutes the majority of the APK size (58 MBs). This is our 
  trained machine learning model and where the magic comes from. It's a  
 pre-built TensorFlow <a href="https://www.tensorflow.org/versions/master/api_docs/python/framework.html#Graph">Graph</a> 
  describing the exact operations needed to compute a classification from 
  input image data. This Graph is serialized and encoded into binary with 
  Google's <a href="https://developers.google.com/protocol-buffers/?hl=en">Protocol Buffers</a> so it can be deserialized across different platforms (think of it as a binary-encoded JSON file). </p></li> 
 <li><p><code>imagenet_comp_graph_label_strings.txt</code>- this contains 
  the 1000 classifications that the output of the model corresponds to  
 (e.g. "vending machine", "water bottle", "coffee mug"). These  
 classifications are <a href="http://image-net.org/challenges/LSVRC/2014/browse-synsets">defined</a> by the ImageNet Large Scale Visual Recognition Challenge which the model was built to compete in.</p></li> 
 </ol> 
  
 <p>The model here is what's known as a deep <a href="https://youtu.be/bEUX_56Lojc?t=2m53s">convolutional neural network</a>. It is built in the Inception architecture described in <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf">Going Deeper with Convolutions</a>. 
  Convolutional neural networks are some of the most popular models in  
 deep learning. They have been very successful in image recognition (so  
 much so, that most highly ranked teams in the competition used them).</p> 
  
 <p>The model is read from the file and fed into TensorFlow when the app starts up. This <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/jni/tensorflow_jni.cc#L50">code</a> 
   is actually really interesting to read and see how to communicate with 
  tensorflow (if you run the app with your device connected to your  
 computer, you can see these helpful log messages printed in logcat).</p> 
  
 <h2>Build System</h2> 
  
 <p>The Android app example is not built the traditional Gradle way.  
 Because the app has to contain NDK elements as well as TensorFlow  
 itself, a more elaborate build system was utilized. The example is  
 configured to be built with Google's <a href="http://bazel.io/">Bazel</a> build system running from the TensorFlow root directory.</p> 
  
 <p>The <a href="https://github.com/tensorflow/tensorflow/blob/master/WORKSPACE">WORKSPACE</a> file in the root directory specifies the main parameters of the project. The <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/BUILD">BUILD</a> file in the Android directory instructs the build system to build the Java and C++ files of the app.</p> 
  
 <h2>The Possibilities</h2> 
  
 <p>Using a trained model in your app seems to be the lowest hanging  
 fruit for mobile TensorFlow apps at the moment. While you can probably  
 train a model on Android, mobile devices are not well suited for the  
 intensive processing required by complex models with larger training  
 sets.</p> 
  
 <p>Want to learn more about machine learning? Consider checking out the <a href="https://www.coursera.org/learn/machine-learning/">Machine Learning course on Coursera</a>. There's also a good discussion in <a href="https://www.reddit.com/r/MachineLearning/">/r/MachineLearning</a> here: <a href="https://www.reddit.com/r/MachineLearning/comments/3wno5e/in_your_experience_which_machine_learning_course/">In your experience, which machine learning course on Coursera (or other MOOC web site) was the best?</a>.</p> 
  
 <p>Want to comment? <a href="https://www.reddit.com/r/androiddev/comments/3zpkb6/supercharging_android_apps_with_tensorflow/">/r/androiddev</a>, <a href="https://news.ycombinator.com/item?id=10850113">Hacker News</a>.</p> 
  
   </div> 
  
   <div class="date"> 
     Written on January  6, 2016 
   </div> 
  
    
 </article> 
  
     </div> 
  
     <div class="wrapper-footer"> 
       <div class="container"> 
         <footer class="footer"> 
            
  
  
  
 <a href="https://github.com/jalammar"><i class="svg-icon github"></i></a> 
  
 <a href="https://www.linkedin.com/in/jalammar"><i class="svg-icon linkedin"></i></a> 
  
  
 <a href="https://www.twitter.com/jalammar"><i class="svg-icon twitter"></i></a> 
  
  
  
         </footer> 
       </div> 
     </div> 
  
      
 	<!-- Google Analytics --> 
 	<script async="" src="Supercharging%20Android%20Apps%20With%20TensorFlow%20%28Google%27s%20Open%20Source%20Machine%20Learning%20Library%29%20%E2%80%93%20J%20Alammar%20%E2%80%93%20Explorations%20in%20touchable%20pixels%20and%20intelligent%20androids_files/analytics.js"></script><script> 
 		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ 
 		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), 
 		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) 
 		})(window,document,'script','//www.google-analytics.com/analytics.js','ga'); 
  
 		ga('create', 'UA-71956058-1', 'auto'); 
 		ga('send', 'pageview', { 
 		  'page': '/Supercharging-android-apps-using-tensorflow/', 
 		  'title': 'Supercharging Android Apps With TensorFlow (Google\'s Open Source Machine Learning Library)' 
 		}); 
 	</script> 
 	<!-- End Google Analytics --> 
  
  
    
  
 <script src="index-file/high.js"></script></body></html>